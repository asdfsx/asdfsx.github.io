<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka on asdfsx</title>
    <link>https://asdfsx.github.io/tags/kafka/index.xml</link>
    <description>Recent content in Kafka on asdfsx</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <atom:link href="https://asdfsx.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kafka</title>
      <link>https://asdfsx.github.io/post/messagequeue/Kafka/</link>
      <pubDate>Sat, 25 Mar 2017 21:37:50 +0800</pubDate>
      
      <guid>https://asdfsx.github.io/post/messagequeue/Kafka/</guid>
      <description>

&lt;p&gt;随便写写Kafka，并且大俗特俗的从安装操作开始写起。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的安装&#34;&gt;Kafka 的安装&lt;/h1&gt;

&lt;p&gt;首先要有 jdk！
其次要有 zookeeper！不过kafka的发行版压缩包中，已经集成了zookeeper。
从官网下载最新版的Kafka，解压后就可以直接使用了。&lt;/p&gt;

&lt;p&gt;启动zookeeper：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动Kafka&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-server-start.sh -daemon config/server.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样一个单节点的Kafka就启动了。早期的版本启动的时候还需要使用 nohup 来放到后台。现在只需要带 -daemon 参数了。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的操作&#34;&gt;Kafka 的操作&lt;/h1&gt;

&lt;p&gt;只列几个常用的命令，更多的命令可以到官网上去翻文档。&lt;/p&gt;

&lt;h3 id=&#34;创建topic&#34;&gt;创建topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic etl-kafka --partitions 24 --replication-factor 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;列出所有的topic&#34;&gt;列出所有的topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --list 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查看topic信息&#34;&gt;查看topic信息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic etl-kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试发送消息&#34;&gt;测试发送消息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-console-producer.sh --broker-list localhost:9092 --topic etl-kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试接受消息&#34;&gt;测试接受消息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic etl-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上是最常用的命令，此外还有些管理 topic 的命令，如&lt;/p&gt;

&lt;h3 id=&#34;修改-topic&#34;&gt;修改 topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper zk_host:port/chroot --alter --topic my_topic_name --partitions 40
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;删除-topic&#34;&gt;删除 topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic my_topic_name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有关于集群管理、consumer管理、数据平衡等的命令。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的设计&#34;&gt;Kafka 的设计&lt;/h1&gt;

&lt;h3 id=&#34;topic&#34;&gt;Topic&lt;/h3&gt;

&lt;p&gt;kakfa 启动后，首先要创建Topic，才能接收数据。Topic 可以看作是一个个目录，用来存放消息。每个Topic都可以有多个 producer，consumer。&lt;/p&gt;

&lt;h3 id=&#34;partition&#34;&gt;Partition&lt;/h3&gt;

&lt;p&gt;Topic 中的消息是分区存放的，具体有多少个区，可以在创建的时候指定。当 producer 在向 Kafka 中写入数据的时候，通过指定的分区ID、或者计算出来的分区ID，将消息放入各个分区中。分区是有序的，当 producer 向分区写入消息时，每条记录都会有获得一个唯一的编号 offset。&lt;/p&gt;

&lt;p&gt;如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/log_anatomy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当 consumer 获取消息时，就可以根据分区ID，offset 去请求数据，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/log_consumer.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;集群&#34;&gt;集群&lt;/h3&gt;

&lt;p&gt;集群的信息由 zookeeper 来维护。节点信息、topic信息 等都会保存在zookeeper上。&lt;/p&gt;

&lt;p&gt;分区是散布在集群中的多个节点上的，并且在创建Topic时，通过设置 replication 来提高可用性。&lt;/p&gt;

&lt;p&gt;如果replication 设为1，表示没有复制集，数据只有一份。这种情况下，一个分区只会存在在一个节点上，换句话说，就是分区在整个集群中是唯一的。如果节点不可用，这个节点上所有的分区就都不可用了。&lt;/p&gt;

&lt;p&gt;如果replication 设为2，表示有一个复制集。这种情况下，分区会存在在两个节点上（设置replication的前提是，集群有多个节点，单节点集群无法设置复制集）。其中一个作为 leader ，另一个作为 flower 。leader 负责所有的读写请求，flower负责同步数据。当 leader 不可用的时候，flower 会取代旧 leader 作为新 leader。（非常像raft）&lt;/p&gt;

&lt;h3 id=&#34;producer&#34;&gt;Producer&lt;/h3&gt;

&lt;p&gt;负责将数据写入 kafka。Kafka 集群不关心消息会被放入哪个分片，这个逻辑由producer来实现。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以根据需要使用round-robin来将消息逐个放入不同的分区；&lt;/li&gt;
&lt;li&gt;可以根据业务需求将消息放入指定的分区&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;consumer&#34;&gt;Consumer&lt;/h3&gt;

&lt;p&gt;从根本上讲 Kafka 集群不关心消费者如何消费数据。只要 Consumer 知道 Topic、分区ID、offset 就可以发起请求获取数据。这样就带来一个问题 offset 的管理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过去 Kafka 是不管 offset 的，一切都由用户来管理。&lt;/li&gt;
&lt;li&gt;后来为了方便用户，将 offset 保存在zookeeper里，并引入了 consumer group 的概念：一个 group 内的consumer共享一组offset。&lt;/li&gt;
&lt;li&gt;现在又提供了新的 offset 管理方式：创建一个内部队列用来维护偏移量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从用户使用角度来讲，由kafka管理 offset 可能是个发展趋势。不过 offset 仍然可以考虑自己管理一份，这样遇到一些异常情况，可以用自己管理的 offset 来消费过去的旧数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/consumer-groups.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用swarm在mac上搭建开发环境</title>
      <link>https://asdfsx.github.io/post/docker/%E4%BD%BF%E7%94%A8swarm%E5%9C%A8mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Sat, 18 Feb 2017 10:12:39 +0800</pubDate>
      
      <guid>https://asdfsx.github.io/post/docker/%E4%BD%BF%E7%94%A8swarm%E5%9C%A8mac%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>

&lt;h1 id=&#34;源起&#34;&gt;源起&lt;/h1&gt;

&lt;p&gt;docker并不是新技术。作为 golang 社区内的旗舰级的项目，从诞生之初就吸引了很多人的瞩目，甚至可以说是获得了所有 golang 社区的人多瞩目吧。同时对推广 golang 也起了很大的作用。作为从一直关注着 golang 的人，大概2年前就开始尝试使用它了。不过由于其依赖 linux 的多项特性，导致在 mac 上使用必须要借助虚拟机，体验总是要差一点。最近经人提醒发现新的 docker for mac 可以不借助虚拟机就可以在 mac 上提供与 linux 上同样的体验，大喜！遂卸载虚拟机，打算用新软件搭个测试环境玩耍一下。&lt;/p&gt;

&lt;h1 id=&#34;安装&#34;&gt;安装&lt;/h1&gt;

&lt;p&gt;超级简单，照着说明来就好。顺便装上了 kitematic。这个确实也非常好用。&lt;/p&gt;

&lt;h1 id=&#34;目标&#34;&gt;目标&lt;/h1&gt;

&lt;p&gt;将一套以前用 python 实现的 kafka producer程序，移植到 golang 上。测试新程序的异常情况处理（特指连接失败的处理）。
然后就被坑掉了。&lt;/p&gt;

&lt;h1 id=&#34;坑1-网络的问题&#34;&gt;坑1 网络的问题&lt;/h1&gt;

&lt;p&gt;最初只是想通过 docker 启动一个单点的 kafka，程序通过本地网络直接访问就可以了。通过之前安装的 kitematic 从 hub.docker.com 上下载了 spotify/kafka 镜像，并直接启动容器。通过kitematic连接到容器内，各项命令执行正常。但是执行程序的时候却发现，总是第一次连接成功后，后边的所有连接都是失败的。通过日志发现程序在第一次成功连接 kafka 之后，连接地址发生了变更，变成了容器内部的地址（直观的现象就是，端口从 kitematic 随机生成的 12345 变成了 9092）。然后又尝试了手动用 &amp;ndash;net=host 方式启动，结果彻底连不上了。&lt;/p&gt;

&lt;p&gt;在对 github.com/shopify/sarama 简单的分析以后，发现它的连接过程是这样的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首次连接，根据配置信息连接服务器&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;连接成功后，从服务器获取broker信息&lt;/li&gt;
&lt;li&gt;根据获得到的broker信息，连接其余的broker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;问题就出现在最后一步上，服务器返回的broker信息中，网络地址都是容器内部的网络，没有办法从容器网络外部直接连接的。&lt;/p&gt;

&lt;p&gt;通过在github上查 issue， google 上查资料，有了以下不负责任的猜想：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;目前的 docker for mac 使用了自己搞的 github.com/docker/hyperkit 来实现轻量级的虚拟化。从项目的说明可以看到，其基于 github.com/mist64/xhyve，借助了 mac os 自身的 hypervisor.framework 来实现虚拟化。在 developer.apple.com 上可以看到相关的说明和 api refrence。它是 OS X v10.10 新增的一个功能，从 api 上来看，可以实现对 cpu 和 mem 的简单控制
，并没有提供对网络的控制。网络这块是 xhyve 自己通过 virto-net 实现的。这可能也是导致网络这块体验比较差的原因吧。完善网络还需要花不少时间。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;测试还是要继续，从外部连接容器网络有问题，那就把测试程序也放到容器环境中去。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;上SWARM吧，骚年！&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;用swarm解决网络问题&#34;&gt;用SWARM解决网络问题&lt;/h1&gt;

&lt;p&gt;业界已有很多容器集群方案：kubernetes、mesos、swarm等。各有优势，选择swarm，主要原因还是方便，直接与docker集成。顺便吐槽，容器的江湖也是乱啊！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;下载测试用到的镜像&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  docker pull nginx
  docker pull spotify/kafka:latest
  docker pull prom/busybox:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;在本地创建swarm&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  docker swarm init
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;创建 overlay 网络&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  docker network  create \
    --driver overlay \
    --subnet 10.0.9.0/24 \
    --opt encrypted \
    my-network
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;简单测试一下 overlay 网络，以及swarm中的服务发现&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动一个 nginx 服务，并挂到 overlay 网络上&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker service create \
  --replicas 1 \
  --name my-web \
  --network my-network \
  nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;检查服务&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker service ps my-web
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;检查网络&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker network inspect my-network
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;使用busybox检查服务发现，其实就是网络中的dns&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker service create \
  --name dnstest \
  --network my-network \
  busybox \
  sleep 3000
  
docker service ps dnstest

docker exec -it dnstest.1.k8pjka8c9ikrpeje6spm6z8b5 sh

nslookup my-web
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;启动 kafka 服务&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  docker service create \
    --name kafka \
    --network my-network \
    spotify/kafka:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;测试 kafka
用测试 my-web 的方法测试 kafka&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;关闭服务&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  docker service rm my-web
  docker service rm kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;测试程序打包&#34;&gt;测试程序打包&lt;/h1&gt;

&lt;p&gt;golang 支持交叉编译，也就是说我在 mac 上就可以直接编译出 linux 上可以使用的可执行程序。这真是极大的方便了开发人员。只需要&lt;code&gt;GOOS=linux GOARCH=amd64 go build ${LDFLAGS} ${PACKAGE}&lt;/code&gt;就可以获得需要的可执行程序。然后简单的打包到镜像中就可以了。然后如愿以偿的掉入&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;坑2-时区的问题&#34;&gt;坑2 时区的问题&lt;/h1&gt;

&lt;p&gt;鉴于 golang 的可执行文件只是依赖 glibc，打包时选择了官方busybox作为基础镜像，好处就是小！小到连时区的支持都缩减到只有 UTC 一个，然后程序执行的时候就悲剧了。找到了最简单的一个解决办法是，设置环境变量&lt;code&gt;TZ&lt;/code&gt;，设为&lt;code&gt;CST-8&lt;/code&gt;表示中国标准时间，设为&lt;code&gt;JST-9&lt;/code&gt;表示日本标准时间。这个对于 date 命令很好使，但是对于编译好的 golang 程序顶个球用。只能选择另外一个办法，换一个带时区支持的 &lt;code&gt;prom/busybox&lt;/code&gt; 镜像，然后在Dockerfile中增加一个命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN mv /etc/localtime /etc/localtime.bak &amp;amp;&amp;amp; \
    ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;时区问题搞定，测试顺利进行&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>