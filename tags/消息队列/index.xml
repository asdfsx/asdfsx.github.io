<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>消息队列 on asdfsx</title>
    <link>https://asdfsx.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml</link>
    <description>Recent content in 消息队列 on asdfsx</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <atom:link href="https://asdfsx.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kafka</title>
      <link>https://asdfsx.github.io/post/messagequeue/Kafka/</link>
      <pubDate>Sat, 25 Mar 2017 21:37:50 +0800</pubDate>
      
      <guid>https://asdfsx.github.io/post/messagequeue/Kafka/</guid>
      <description>

&lt;p&gt;随便写写Kafka，并且大俗特俗的从安装操作开始写起。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的安装&#34;&gt;Kafka 的安装&lt;/h1&gt;

&lt;p&gt;首先要有 jdk！
其次要有 zookeeper！不过kafka的发行版压缩包中，已经集成了zookeeper。
从官网下载最新版的Kafka，解压后就可以直接使用了。&lt;/p&gt;

&lt;p&gt;启动zookeeper：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动Kafka&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-server-start.sh -daemon config/server.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样一个单节点的Kafka就启动了。早期的版本启动的时候还需要使用 nohup 来放到后台。现在只需要带 -daemon 参数了。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的操作&#34;&gt;Kafka 的操作&lt;/h1&gt;

&lt;p&gt;只列几个常用的命令，更多的命令可以到官网上去翻文档。&lt;/p&gt;

&lt;h3 id=&#34;创建topic&#34;&gt;创建topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic etl-kafka --partitions 24 --replication-factor 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;列出所有的topic&#34;&gt;列出所有的topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --list 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;查看topic信息&#34;&gt;查看topic信息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic etl-kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试发送消息&#34;&gt;测试发送消息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-console-producer.sh --broker-list localhost:9092 --topic etl-kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;测试接受消息&#34;&gt;测试接受消息&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic etl-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上是最常用的命令，此外还有些管理 topic 的命令，如&lt;/p&gt;

&lt;h3 id=&#34;修改-topic&#34;&gt;修改 topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper zk_host:port/chroot --alter --topic my_topic_name --partitions 40
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;删除-topic&#34;&gt;删除 topic&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic my_topic_name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有关于集群管理、consumer管理、数据平衡等的命令。&lt;/p&gt;

&lt;h1 id=&#34;kafka-的设计&#34;&gt;Kafka 的设计&lt;/h1&gt;

&lt;h3 id=&#34;topic&#34;&gt;Topic&lt;/h3&gt;

&lt;p&gt;kakfa 启动后，首先要创建Topic，才能接收数据。Topic 可以看作是一个个目录，用来存放消息。每个Topic都可以有多个 producer，consumer。&lt;/p&gt;

&lt;h3 id=&#34;partition&#34;&gt;Partition&lt;/h3&gt;

&lt;p&gt;Topic 中的消息是分区存放的，具体有多少个区，可以在创建的时候指定。当 producer 在向 Kafka 中写入数据的时候，通过指定的分区ID、或者计算出来的分区ID，将消息放入各个分区中。分区是有序的，当 producer 向分区写入消息时，每条记录都会有获得一个唯一的编号 offset。&lt;/p&gt;

&lt;p&gt;如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/log_anatomy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当 consumer 获取消息时，就可以根据分区ID，offset 去请求数据，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/log_consumer.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;集群&#34;&gt;集群&lt;/h3&gt;

&lt;p&gt;集群的信息由 zookeeper 来维护。节点信息、topic信息 等都会保存在zookeeper上。&lt;/p&gt;

&lt;p&gt;分区是散布在集群中的多个节点上的，并且在创建Topic时，通过设置 replication 来提高可用性。&lt;/p&gt;

&lt;p&gt;如果replication 设为1，表示没有复制集，数据只有一份。这种情况下，一个分区只会存在在一个节点上，换句话说，就是分区在整个集群中是唯一的。如果节点不可用，这个节点上所有的分区就都不可用了。&lt;/p&gt;

&lt;p&gt;如果replication 设为2，表示有一个复制集。这种情况下，分区会存在在两个节点上（设置replication的前提是，集群有多个节点，单节点集群无法设置复制集）。其中一个作为 leader ，另一个作为 flower 。leader 负责所有的读写请求，flower负责同步数据。当 leader 不可用的时候，flower 会取代旧 leader 作为新 leader。（非常像raft）&lt;/p&gt;

&lt;h3 id=&#34;producer&#34;&gt;Producer&lt;/h3&gt;

&lt;p&gt;负责将数据写入 kafka。Kafka 集群不关心消息会被放入哪个分片，这个逻辑由producer来实现。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以根据需要使用round-robin来将消息逐个放入不同的分区；&lt;/li&gt;
&lt;li&gt;可以根据业务需求将消息放入指定的分区&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;consumer&#34;&gt;Consumer&lt;/h3&gt;

&lt;p&gt;从根本上讲 Kafka 集群不关心消费者如何消费数据。只要 Consumer 知道 Topic、分区ID、offset 就可以发起请求获取数据。这样就带来一个问题 offset 的管理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过去 Kafka 是不管 offset 的，一切都由用户来管理。&lt;/li&gt;
&lt;li&gt;后来为了方便用户，将 offset 保存在zookeeper里，并引入了 consumer group 的概念：一个 group 内的consumer共享一组offset。&lt;/li&gt;
&lt;li&gt;现在又提供了新的 offset 管理方式：创建一个内部队列用来维护偏移量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从用户使用角度来讲，由kafka管理 offset 可能是个发展趋势。不过 offset 仍然可以考虑自己管理一份，这样遇到一些异常情况，可以用自己管理的 offset 来消费过去的旧数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kafka.apache.org/11/images/consumer-groups.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>消息队列</title>
      <link>https://asdfsx.github.io/post/messagequeue/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Sat, 25 Feb 2017 21:02:43 +0800</pubDate>
      
      <guid>https://asdfsx.github.io/post/messagequeue/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      <description>&lt;p&gt;关于消息队列其实已经有很多文章了，简单摘抄一些。
以下内容来自&lt;a href=&#34;http://tech.meituan.com/mq-design.html&#34;&gt;美团技术点评：消息队列设计精要&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。

常见的使用场景：
解耦
最终一致性
广播
错峰与流控

消息队列基本功能：
RPC通信协议
高可用
服务端承载消息堆积的能力
存储子系统的选择
消费关系解析

队列高级特性设计：
可靠投递（最终一致性）
消费确认
事务


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正式接触过的消息队列有Kafka、RabbitMQ，其余还稍微了解过ZeroMQ、nsq。它们都有其独特之处，都有各自的使用场景。而使用场景决定了消息队列产品的选择。&lt;/p&gt;

&lt;p&gt;Kafka 是在搞 ETL 项目时用到的。其设计初衷是高吞吐，所以放弃了传统消息队列的设计思路（维护消息状态，保证消息一次发送&amp;hellip;等等特性），取而代之的消息的持久化、分片、偏移量等设计思路。&lt;/p&gt;

&lt;p&gt;RabbitMQ 是在研究 OpenStack时接触到的。主要作用是进行 python 的进程间通讯：所有的进程都会连接 RabbitMQ；控制节点会通过RabbitMQ下发命令；计算节点会通过RabbitMQ回传命令执行情况、或者是本机的信息。选择RabbitMQ，应该是看中了其可以保证消息的到达的能力。&lt;/p&gt;

&lt;p&gt;而随着Golang社区的发展，也开始有人不断的制造新轮子，前面提到的NSQ就是其中之一，此外还有一个NATS。&lt;/p&gt;

&lt;p&gt;另外Rust社区也在不断的发展中，估计也会诞生出一些新的轮子，之后会持续关注这些新轮子。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>